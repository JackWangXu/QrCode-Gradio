import json
from typing import Optional

import torch
import gradio as gr
from PIL import Image
import qrcode
from pathlib import Path
from multiprocessing import cpu_count
import requests
import io
import os
from PIL import Image

from diffusers import (
    StableDiffusionPipeline,
    StableDiffusionControlNetImg2ImgPipeline,
    ControlNetModel,
    DDIMScheduler,
    DPMSolverMultistepScheduler,
    DEISMultistepScheduler,
    HeunDiscreteScheduler,
    EulerDiscreteScheduler,
)



API_KEY = "o5mxxS7YRCjTF3S1ZOKqNLBb"
SECRET_KEY = "Xw7tX3CNw3Nm1V4YOyFwpHhywypXjTBX"


def call_wenxin_api(text):
    url = "https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/yi_34b_chat?access_token=" + get_access_token()


    headers = {
        'Content-Type': 'application/json'
    }

    # åºåˆ—åŒ– JSON è¯·æ±‚ä½“
    json_payload = json.dumps({
        "messages": [
            {
                "role": "user",
                "content": text
            }
        ]
    })

    # æ£€æŸ¥ JSON åºåˆ—åŒ–åçš„é•¿åº¦ï¼Œå¹¶ç¡®ä¿å…¶ä¸ºå¥‡æ•°
    if len(json_payload) % 2 == 0:
        # åœ¨ JSON å­—ç¬¦ä¸²çš„æœ«å°¾æ·»åŠ ä¸€ä¸ªç©ºæ ¼ï¼ˆæˆ–å…¶ä»–å­—ç¬¦ï¼‰
        json_payload += " "

        # å‘é€è¯·æ±‚ï¼Œè¿™é‡Œç›´æ¥ä½¿ç”¨ json_payload è€Œä¸æ˜¯ payload
    response = requests.post(url, headers=headers, data=json_payload)

    # è¾“å‡ºå“åº”å†…å®¹
    print(response.text)
    return response.text  # è¿”å›å“åº”å†…å®¹è€Œä¸æ˜¯responseå¯¹è±¡


def get_access_token():
    """
    ä½¿ç”¨ AKï¼ŒSK ç”Ÿæˆé‰´æƒç­¾åï¼ˆAccess Tokenï¼‰
    :return: access_tokenï¼Œæˆ–æ˜¯None(å¦‚æœé”™è¯¯)
    """
    url = "https://aip.baidubce.com/oauth/2.0/token"
    params = {"grant_type": "client_credentials", "client_id": API_KEY, "client_secret": SECRET_KEY}
    return str(requests.post(url, params=params).json().get("access_token"))


def generate_prompt(name):
    prompt_template = "å‡è®¾ä½ æ˜¯æç¤ºè¯ç”Ÿæˆä¸“å®¶ï¼Œè¯·æ¨¡ä»¿ä¸‹é¢çš„å‡ ä¸ªæç¤ºè¯ï¼š1.A sky view of a colorful lakes and rivers flowing through the desert  2.Bright sunshine coming through the cracks of a wet, cave wall of big rocks  3.Sky view of highly aesthetic, ancient greek thermal baths  in beautiful nature   æ¯å½“æˆ‘è¾“å…¥ä¸€ä¸ªè¯è¯­çš„æ—¶å€™ è¯·å¸®æˆ‘ç”Ÿæˆä¸€æ®µç±»ä¼¼ä¸Šé¢æ ¼å¼ä¹‹ä¸€çš„è‹±è¯­æç¤ºè¯,è¦æ±‚é•¿åº¦ä¸è¶…è¿‡15ä¸ªå•è¯ï¼Œæ¯æ¬¡åªèƒ½ç”Ÿæˆä¸€å¥è¯å¼€å¤´ä¸èƒ½æºå¸¦åºå·ï¼Œæˆ‘è¾“å…¥çš„æ˜¯{}"
    input_for_api = prompt_template.format(name)
    print('-------å¼€å§‹å‡†å¤‡è°ƒç”¨æ¥å£')
    # å‡è®¾call_wenxin_apiå‡½æ•°è¿”å›çš„æ˜¯ä¸€ä¸ªJSONæ ¼å¼çš„å­—ç¬¦ä¸²
    response_str = call_wenxin_api(input_for_api)

    # è§£æJSONå­—ç¬¦ä¸²ä¸ºPythonå­—å…¸
    response_dict = json.loads(response_str)

    # æå–resultå­—æ®µçš„å†…å®¹
    result_content = response_dict.get('result', 'æœªæ‰¾åˆ°resultå­—æ®µ')

    # æ‰“å°æå–åˆ°çš„å†…å®¹
    print(result_content)

    # è¿”å›æå–åˆ°çš„å†…å®¹
    return result_content,result_content

qrcode_generator = qrcode.QRCode(
    version=1,
    error_correction=qrcode.ERROR_CORRECT_H,
    box_size=10,
    border=4,
)

controlnet = ControlNetModel.from_pretrained(
    "./control_v1p_sd15_qrcode", torch_dtype=torch.float16
)

pipe = StableDiffusionControlNetImg2ImgPipeline.from_pretrained(
    "./stable-diffusion-v1-5",
    controlnet=controlnet,
    safety_checker=None,
    torch_dtype=torch.float16,
).to("cuda")
pipe.enable_xformers_memory_efficient_attention()


def resize_for_condition_image(input_image: Image.Image, resolution: int):
    input_image = input_image.convert("RGB")
    W, H = input_image.size
    k = float(resolution) / min(H, W)
    H *= k
    W *= k
    H = int(round(H / 64.0)) * 64
    W = int(round(W / 64.0)) * 64
    img = input_image.resize((W, H), resample=Image.LANCZOS)
    return img


SAMPLER_MAP = {
    "DPM++ Karras SDE": lambda config: DPMSolverMultistepScheduler.from_config(config, use_karras=True, algorithm_type="sde-dpmsolver++"),
    "DPM++ Karras": lambda config: DPMSolverMultistepScheduler.from_config(config, use_karras=True),
    "Heun": lambda config: HeunDiscreteScheduler.from_config(config),
    "Euler": lambda config: EulerDiscreteScheduler.from_config(config),
    "DDIM": lambda config: DDIMScheduler.from_config(config),
    "DEIS": lambda config: DEISMultistepScheduler.from_config(config),
}


def inference(
    qr_code_content: str,
    prompt: str,
    negative_prompt: str,
    guidance_scale: float = 10.0,
    controlnet_conditioning_scale: float = 2.0,
    strength: float = 0.8,
    seed: int = -1,
    init_image: Optional[Image.Image] = None,
    qrcode_image: Optional[Image.Image] = None,
    use_qr_code_as_init_image = True,
    sampler = "DPM++ Karras SDE",
):
    if prompt is None or prompt == "":
        raise gr.Error("Prompt is required")

    if qrcode_image is None and qr_code_content == "":
        raise gr.Error("QR Code Image or QR Code Content is required")

    pipe.scheduler = SAMPLER_MAP[sampler](pipe.scheduler.config)

    generator = torch.manual_seed(seed) if seed != -1 else torch.Generator()

    if qr_code_content != "" or qrcode_image.size == (1, 1):
        print("Generating QR Code from content")
        qr = qrcode.QRCode(
            version=1,
            error_correction=qrcode.constants.ERROR_CORRECT_H,
            box_size=10,
            border=4,
        )
        qr.add_data(qr_code_content)
        qr.make(fit=True)

        qrcode_image = qr.make_image(fill_color="black", back_color="white")
        qrcode_image = resize_for_condition_image(qrcode_image, 768)
    else:
        print("Using QR Code Image")
        qrcode_image = resize_for_condition_image(qrcode_image, 768)

    # hack due to gradio examples
    init_image = qrcode_image

    out = pipe(
        prompt=prompt,
        negative_prompt=negative_prompt,
        image=qrcode_image,
        control_image=qrcode_image,  # type: ignore
        width=768,  # type: ignore
        height=768,  # type: ignore
        guidance_scale=float(guidance_scale),
        controlnet_conditioning_scale=float(controlnet_conditioning_scale),  # type: ignore
        generator=generator,
        strength=float(strength),
        num_inference_steps=40,
    )
    return out.images[0]  # type: ignore


with gr.Blocks() as blocks:
    gr.Markdown(
        """
#                                 YumChina QRCode AI Art Generator
## ğŸ’¡ å¦‚ä½•ä½¿ç”¨ç™¾èƒœä¸­å›½è‰ºæœ¯äºŒç»´ç ç”Ÿæˆå™¨ç”Ÿæˆæ¼‚äº®çš„äºŒç»´ç 
æˆ‘ä»¬ä½¿ç”¨äºŒç»´ç å›¾åƒä½œä¸ºåˆå§‹å›¾åƒå’Œæ§åˆ¶å›¾åƒï¼Œè¿™å…è®¸æ‚¨ç”Ÿæˆä¸æ‚¨æä¾›çš„æç¤ºéå¸¸è‡ªç„¶åœ°èåˆåœ¨ä¸€èµ·çš„äºŒç»´ç ã€‚
å¼ºåº¦å‚æ•°å®šä¹‰äº†æ·»åŠ åˆ°äºŒç»´ç ä¸­çš„å™ªå£°é‡ï¼Œå™ªå£°äºŒç»´ç éšåé€šè¿‡Controlnetå¼•å¯¼å‘æ‚¨çš„æç¤ºå’ŒäºŒç»´ç å›¾åƒã€‚
ä½¿ç”¨é«˜å¼ºåº¦å€¼åœ¨0.8åˆ°0.95ä¹‹é—´ï¼Œå¹¶é€‰æ‹©ä¸€ä¸ªè°ƒèŠ‚å°ºåº¦åœ¨0.6åˆ°2.0ä¹‹é—´ã€‚
è¿™ç§æ¨¡å¼å¯ä»¥è¯´å®ç°äº†ç¾è§‚ä¸Šæœ€å¸å¼•äººçš„äºŒç»´ç å›¾åƒï¼Œä½†ä¹Ÿéœ€è¦æ›´å¤šåœ°è°ƒæ•´æ§åˆ¶ç½‘çš„è°ƒèŠ‚å°ºåº¦å’Œå¼ºåº¦å€¼ã€‚å¦‚æœç”Ÿæˆçš„å›¾åƒçœ‹èµ·æ¥å¤ªåƒåŸå§‹äºŒç»´ç ï¼Œè¯·ç¡®ä¿è½»è½»å¢åŠ å¼ºåº¦å€¼å¹¶å‡å°‘è°ƒèŠ‚å°ºåº¦ã€‚åŒæ—¶ï¼Œè¯·æŸ¥çœ‹ä¸‹é¢çš„examplesã€‚

                """
    )

    with gr.Row():
        with gr.Column():
            qr_code_content = gr.Textbox(
                label="äºŒç»´ç å†…å®¹",
                info="æ–‡æœ¬ æˆ–è€… URL",
                value="",
            )
            with gr.Accordion(label="QR Code Image (Optional)", open=False):
                qr_code_image = gr.Image(
                    label="QR Code Image (Optional). Leave blank to automatically generate QR code",
                    type="pil",
                )
            fast_prompt = gr.Textbox(
                label="å¿«é€Ÿæç¤ºè¯",
                info="Prompt that guides the generation towards",
            )
            generate_btn = gr.Button("å¿«é€Ÿå¸®ä½ ç”Ÿæˆæç¤ºè¯­")  # æ·»åŠ ä¸€ä¸ªç”Ÿæˆæç¤ºè¯çš„æŒ‰é’®
            prompt = gr.Textbox(
                label="æç¤ºè¯è¯­",
                info="Prompt that guides the generation towards",
            )
            negative_prompt = gr.Textbox(
                label="æ¶ˆææç¤ºè¯",
                value="ugly, disfigured, low quality, blurry, nsfw",
            )
            use_qr_code_as_init_image = gr.Checkbox(label="Use QR code as init image", value=True, interactive=False, info="Whether init image should be QR code. Unclick to pass init image or generate init image with Stable Diffusion 2.1")


            # æ·»åŠ ä¸€ä¸ªéšè—çš„è¾“å‡ºç»„ä»¶ï¼Œç”¨äºè§¦å‘æ›´æ–°ï¼ˆè¿™é‡Œä¸ä¼šåœ¨ç•Œé¢ä¸Šæ˜¾ç¤ºï¼‰
            dummy_output = gr.Textbox(visible=False)

            # è®¾ç½®æŒ‰é’®ç‚¹å‡»äº‹ä»¶
            generate_btn.click(
                generate_prompt,
                inputs=fast_prompt,
                outputs=[fast_prompt, dummy_output]
            )
            with gr.Accordion(label="Init Images (Optional)", open=False, visible=False) as init_image_acc:
                init_image = gr.Image(label="Init Image (Optional). Leave blank to generate image with SD 2.1", type="pil")


            with gr.Accordion(
                label="Params: The generated QR Code functionality is largely influenced by the parameters detailed below",
                open=True,
            ):
                controlnet_conditioning_scale = gr.Slider(
                    minimum=0.0,
                    maximum=5.0,
                    step=0.01,
                    value=1.1,
                    label="Controlnet Conditioning Scale",
                )
                strength = gr.Slider(
                    minimum=0.0, maximum=1.0, step=0.01, value=0.9, label="Strength"
                )
                guidance_scale = gr.Slider(
                    minimum=0.0,
                    maximum=50.0,
                    step=0.25,
                    value=7.5,
                    label="Guidance Scale",
                )
                sampler = gr.Dropdown(choices=list(SAMPLER_MAP.keys()), value="DPM++ Karras SDE", label="Sampler")
                seed = gr.Slider(
                    minimum=-1,
                    maximum=9999999999,
                    step=1,
                    value=2313123,
                    label="Seed",
                    randomize=True,
                )
            with gr.Row():
                run_btn = gr.Button("Run")
        with gr.Column():
            result_image = gr.Image(label="Result Image")
    run_btn.click(
        inference,
        inputs=[
            qr_code_content,
            prompt,
            negative_prompt,
            guidance_scale,
            controlnet_conditioning_scale,
            strength,
            seed,
            init_image,
            qr_code_image,
            use_qr_code_as_init_image,
            sampler,
        ],
        outputs=[result_image],
        concurrency_limit=1
    )

    gr.Examples(
        examples=[
            [
                "http://www.yumchina.com/",
                "A sky view of a colorful lakes and rivers flowing through the desert",
                "ugly, disfigured, low quality, blurry, nsfw",
                7.5,
                1.3,
                0.9,
                5392011833,
                None,
                None,
                True,
                "DPM++ Karras SDE",
            ],
            [
                "http://www.yumchina.com/",
                "Bright sunshine coming through the cracks of a wet, cave wall of big rocks",
                "ugly, disfigured, low quality, blurry, nsfw",
                7.5,
                1.11,
                0.9,
                2523992465,
                None,
                None,
                True,
                "DPM++ Karras SDE",
            ],
            [
                "http://www.yumchina.com/",
                "Sky view of highly aesthetic, ancient greek thermal baths  in beautiful nature",
                "ugly, disfigured, low quality, blurry, nsfw",
                7.5,
                1.5,
                0.9,
                2523992465,
                None,
                None,
                True,
                "DPM++ Karras SDE",
            ],
        ],
        fn=inference,
        inputs=[
            qr_code_content,
            prompt,
            negative_prompt,
            guidance_scale,
            controlnet_conditioning_scale,
            strength,
            seed,
            init_image,
            qr_code_image,
            use_qr_code_as_init_image,
            sampler,
        ],
        outputs=[result_image],
        cache_examples=True,
    )

blocks.queue(max_size=20,api_open=False)

blocks.launch(share=bool(os.environ.get("SHARE", False)), show_api=False)